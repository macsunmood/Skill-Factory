{"cells":[{"metadata":{"id":"v0_oidHDHMDE"},"cell_type":"markdown","source":"# Классификация изображений авто\n\nСоревнование на Kaggle: **[[>](https://www.kaggle.com/c/sf-dl-car-classification)]**\n"},{"metadata":{"id":"6Rbz0ZgoHMDN"},"cell_type":"markdown","source":"# Imports and Settings"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"_kg_hide-input":true,"id":"9yyzSv39HMDG","outputId":"8d083f15-6750-4365-8837-c9793d258bac","collapsed":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"id":"bIBSivzMHMDK","outputId":"ebbb8ff1-fd9e-4fcd-a47f-717c1207d0a7"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\nfrom datetime import timedelta, datetime as dt\nfrom time import time\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications import EfficientNetB0, EfficientNetB3\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import Sequential as S\nfrom sklearn.model_selection import train_test_split\n\n# Увеличим дефолтный размер графиков\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 15, 10\n# Улучшим вид графиков в svg\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\n\nprint(os.listdir(\"../input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"id":"EUmwV5JCHMDP"},"cell_type":"code","source":"# Фиксируем версии всех пакетов для воспроизводимости\n!pip freeze > requirements.txt\n\n# Устаналиваем конкретное значение random seed для воспроизводимости\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0\n\nDATA_PATH = '../input/sf-dl-car-classification/'\nPATH = \"../working/car/\" # рабочая директория\nos.makedirs(PATH, exist_ok=True)\n\nsample_submission = pd.read_csv(DATA_PATH + 'sample-submission.csv')\n\ntrain_df = pd.read_csv(DATA_PATH + 'train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"VPOU0uRMHMDR","outputId":"b9fc85f4-f961-4f32-f99d-5dfb95aab51f"},"cell_type":"code","source":"print('Распаковываем картинки.. ', end='')\n\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(DATA_PATH + data_zip, \"r\") as z:\n        z.extractall(PATH)\n        \nprint('Готово')\nprint(os.listdir(PATH))","execution_count":null,"outputs":[]},{"metadata":{"id":"U6VeW2aoHMDv"},"cell_type":"markdown","source":"---\n# EDA / Анализ данных"},{"metadata":{"trusted":true,"id":"68j0ByyLHMDv","outputId":"22150694-221d-4c2c-a68b-08c09a006ae4","collapsed":true},"cell_type":"code","source":"# Для начала ознакомимся с данными:\nprint(train_df.head())\nprint()\nprint(train_df.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"5vLvJ-8yHMDy","collapsed":true},"cell_type":"code","source":"train_df.Category","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"pdw8bHrfHMD3","collapsed":true},"cell_type":"code","source":"train_df.Category.value_counts().plot(kind='barh', figsize=(3, 3));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Распределение классов достаточно равномерное - это хорошо"},{"metadata":{"_kg_hide-input":true,"trusted":true,"id":"uetiiVWrHMD5","collapsed":true},"cell_type":"code","source":"print('Примеры картинок (random samples):')\nplt.figure(figsize=(12, 8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH + f'train/{random_image_cat[index]}/{path}')\n    plt.subplot(3, 3, index + 1)\n    plt.imshow(im)\n    plt.title('Class: ' + str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"3-d5NNY_HMD8"},"cell_type":"markdown","source":"Посмотрим на пример картинки и её размер:"},{"metadata":{"trusted":true,"id":"RkYEk9rCHMD9","collapsed":true},"cell_type":"code","source":"image = PIL.Image.open(PATH + '/train/0/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","execution_count":null,"outputs":[]},{"metadata":{"id":"5LoFjPIRHMEA"},"cell_type":"markdown","source":"---\n# Подготовка данных"},{"metadata":{"id":"KIsbr6kgHMED"},"cell_type":"markdown","source":"### Data Augmentation\nВыполним аугментацию данных, что особенно полезно, если сэмплов не очень много."},{"metadata":{"trusted":true,"id":"UOFlGSyPHMEG"},"cell_type":"code","source":"# Создание объектов генерации аугментированных изображений\ndef create_datagens():\n    train_datagen = ImageDataGenerator(rotation_range=10,           # диапазон поворота в гр.\n                                       brightness_range=[0.5, 1.5], # изменение яркости\n                                       width_shift_range=0.1,       # диапазон сдвига в ширину\n                                       height_shift_range=0.1,      # диапазон сдвига в высоту\n                                       horizontal_flip=True,        # отражение по горизонтали\n                                       validation_split=VAL_SPLIT)\n\n    test_datagen = ImageDataGenerator()\n    return train_datagen, test_datagen","execution_count":null,"outputs":[]},{"metadata":{"id":"T9MdxK4hHMEP"},"cell_type":"markdown","source":"### Data Generation"},{"metadata":{"trusted":true,"id":"RU6OseIhHMEQ"},"cell_type":"code","source":"# Обертка для генераторов данных\ndef rebuild_generators(): \n    # создаем объекты с аугментацией\n    train_datagen, test_datagen = create_datagens()\n\n    # генератор для тренировочной выборки\n    train_generator = train_datagen.flow_from_directory(\n        PATH + 'train/',    # директория, где расположены папки с картинками \n        target_size=(IMG_SIZE, IMG_SIZE), \n        batch_size=BATCH_SIZE, \n        class_mode='categorical', \n        shuffle=True, \n        seed=RANDOM_SEED, \n        subset='training'\n    )\n\n    # генератор для валидационной выборки\n    validation_generator = train_datagen.flow_from_directory(\n        PATH + 'train/', \n        target_size=(IMG_SIZE, IMG_SIZE), \n        batch_size=BATCH_SIZE, \n        class_mode='categorical', \n        shuffle=True, \n        seed=RANDOM_SEED, \n        subset='validation'\n    ) \n\n    # генератор для тестовых данных\n    test_subgenerator = test_datagen.flow_from_dataframe(\n        dataframe=sample_submission, \n        directory=PATH + 'test_upload/', \n        x_col=\"Id\", \n        y_col=None, \n        target_size=(IMG_SIZE, IMG_SIZE), \n        batch_size=BATCH_SIZE, \n        class_mode=None, \n        shuffle=False, \n        seed=RANDOM_SEED\n    )\n    return train_generator, validation_generator, test_subgenerator","execution_count":null,"outputs":[]},{"metadata":{"id":"2DFhW-lZHMET"},"cell_type":"markdown","source":"---\n# Model"},{"metadata":{"id":"c2NndLHnHMEU"},"cell_type":"markdown","source":"### Callbacks Interface\nhttps://keras.io/callbacks/"},{"metadata":{"trusted":true,"id":"htGpzyCTHMEU"},"cell_type":"code","source":"# Созданим callback для фиксации длительности каждой эпохи\nclass TimingCallback(Callback):\n    def __init__(self):\n        self.logs=[]\n    def on_epoch_begin(self, epoch, logs={}):\n        self.starttime=time()\n    def on_epoch_end(self, epoch, logs={}):\n        t = time() - self.starttime\n        self.logs.append(round(t))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"BNwq9LNqHMEY"},"cell_type":"code","source":"# Определим функцию для создания списка callbacks\ndef recreate_callbacks():\n    timing = TimingCallback()\n    \n    callbacks_list = [# сохранять прогресс обучения модели, чтобы \n                      # позже можно было подгрузить и дообучить модель:\n                      ModelCheckpoint('best_model.hdf5',    \n                                      monitor='val_accuracy', \n                                      verbose=1, \n                                      mode='max', \n                                      save_best_only=True), \n                      \n                      # останавливать процесс обучения, если целевая \n                      # метрика не улучшается `patience` эпох подряд:\n                      EarlyStopping(monitor='val_accuracy', \n                                    patience=4, \n                                    restore_best_weights=True), \n                      # снижать LR, если целевая метрика перестает улучаться\n                      # (вместо него используется LearningRateScheduler)\n#                       ReduceLROnPlateau(monitor='val_loss', \n#                                         factor=0.2, \n#                                         patience=3, \n#                                         min_lr=0.001),\n                      \n                      # постепенно уменьшать LR после каждой эпохи:\n                      LearningRateScheduler(lambda x: LR * LR_DECAY_RATE ** x, \n                                            verbose=1), \n                      \n                      # фиксировать тайминги эпох:\n                      timing]\n    return callbacks_list","execution_count":null,"outputs":[]},{"metadata":{"id":"-z-JbBUqHMEc"},"cell_type":"markdown","source":"### Helper Functions\n\n#### Напишем несколько вспомогательных функций"},{"metadata":{"id":"uEn3PXbmHMEc"},"cell_type":"markdown","source":"#### Для визуализации и статистики:"},{"metadata":{"trusted":true,"id":"YnWV8EUXHMEd"},"cell_type":"code","source":"# Показывает отдельную метрику по эпохам\ndef show_metric(src):\n    print({i + 1: round(src[i], 4) for i in range(len(src))})\n\n# Показывает небольшую статистику прошедшего обучения\ndef show_stats(history):\n    print('TRAINING STATS\\n--------------\\n')\n    print(f'Base model: {base_model.name}; Optimizer: {model.optimizer._name}')\n    print(f'IMG_SIZE: {IMG_SIZE}; BATCH_SIZE: {BATCH_SIZE};', \n          f'LR: {LR}; DROPOUT_RATE: {DROPOUT_RATE}')\n    \n    print('\\nval_accuracy:')\n    va = history.history['val_accuracy']\n    show_metric(va)\n    print('best:', round(max(va), 4))\n    \n    print('\\nTimings:')\n    show_metric(callbacks_list.timing.logs)\n    \n    print('\\nTotal training time:')\n    print(timedelta(seconds=sum(callbacks_list.timing.logs)))\n    \n# Отображение графиков прошедшего обучения\ndef plot_history(history):\n    plt.style.use('Solarize_Light2')\n    \n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(len(acc))\n\n    plt.figure(figsize=(6, 4))\n    plt.plot(epochs, acc, 'b', label='Training acc')\n    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    plt.figure(figsize=(6, 4))\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"803P2-dLHMEh"},"cell_type":"markdown","source":"#### Для рутинных операций с моделью:"},{"metadata":{"trusted":true,"id":"Q5UqfOgfHMEh"},"cell_type":"code","source":"# Сохранение результатов последнего обучения и подгрузка весов лучшей модели\n# (также используется в fine-tuning для шаговых чекпоинтов)\ndef model_save(step=0):\n    model.save(f'../working/model_step{step}.hdf5')\n    model.load_weights('best_model.hdf5')\n    \n# Вспомогательная функция для оценки val_accuracy обученной модели\ndef model_evaluate():\n    scores = model.evaluate_generator(test_generator, verbose=1)\n    print('Accuracy: %.4f' % (scores[1]))","execution_count":null,"outputs":[]},{"metadata":{"id":"n35ivxZG_t4E"},"cell_type":"markdown","source":"#### Для сборки и обучения модели:"},{"metadata":{"trusted":true,"id":"_lujDMt5HMEl"},"cell_type":"code","source":"def model_assembly(base, head):\n    '''\n    Функция производит сборку модели по технике Transfer Learning.\n    За основу берется предобученная сеть, на неё устанавливается новая \n    \"голова\" (head) из свежих слоев, которые понадобятся для решения текущей задачи.\n    '''\n    outputs = base.output\n    \n    for l in head.layers:\n        outputs = l(outputs)\n\n    return Model(inputs=base_model.input, \n                 outputs=outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"yjKyNaCLHMEp"},"cell_type":"code","source":"def model_train(model, epochs):\n    '''\n    Шаблон для операции обучения модели (в т.ч. на шагах fine-tuning).\n    Пересоздает список callbacks и запускает обучение модели.\n    '''\n    callbacks_list = recreate_callbacks()\n    \n    total_count = train_df.count()[0]\n    val_count = int(total_count * VAL_SPLIT)\n    train_count = total_count - val_count\n    steps_per_epoch = train_count // BATCH_SIZE\n\n    return model.fit(train_generator, \n                     steps_per_epoch=steps_per_epoch, \n                     validation_data=validation_generator, \n                     validation_steps=len(validation_generator), \n                     epochs=epochs, \n                     callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"id":"riIiA6EbvMN5"},"cell_type":"markdown","source":"### Hyperparameters\n#### Определим ключевые гиперпараметры модели\n*(в едином месте для удобства дальнейшего перебора)*"},{"metadata":{"trusted":true,"id":"HfTu0HiCHME4","outputId":"e40fda78-75e3-474e-c889-77d64b549c33"},"cell_type":"code","source":"IMG_SIZE             = 112    # размер подаваемого в сеть изображения\nBATCH_SIZE           = 64     # размер Batch\nVAL_SPLIT            = 0.15   # доля валидационной выборки\n\nLR                   = 0.001  # Learning rate\nLR_DECAY_RATE        = 0.9    # скорость \"распада\" Learning rate\nDROPOUT_RATE         = 0.25   # размер Dropout\nEPOCHS               = 15     # количество эпох на обучение\n\n\n# Создадим генераторы данных на основе гиперпараметров\ntrain_generator, validation_generator, test_subgenerator = rebuild_generators()","execution_count":null,"outputs":[]},{"metadata":{"id":"bwgKLSF1HMEy"},"cell_type":"markdown","source":"### Model Assembly\n\n#### Загружаем предобученную на ImageNet сеть EfficientNetB0 \n*(без \"головы\", т.к. будем ставить свою):*"},{"metadata":{"trusted":true,"id":"9gjUvCUJHMEy"},"cell_type":"code","source":"# base_model = InceptionResNetV2(weights='imagenet', \nbase_model = EfficientNetB0(weights='imagenet', \n                            include_top=False, \n                            input_shape=(IMG_SIZE, IMG_SIZE, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"VR3LtPdGHME_"},"cell_type":"code","source":"# Задаем архитектуру \"головы\"\nhead = S([GlobalAveragePooling2D(), \n          \n          Dense(128, use_bias=False, kernel_regularizer='l2'), \n          BatchNormalization(axis=1), \n          Activation('relu'), \n\n          Dropout(DROPOUT_RATE),\n          Dense(10, activation='softmax')])\n\n\n# Собираем модель\nmodel = model_assembly(base_model, head)\n\n# Компилируем\nmodel.compile(loss='categorical_crossentropy', \n#               optimizer=optimizers.Adam(lr=LR), \n#               optimizer=optimizers.Adamax(lr=LR), \n#               optimizer=optimizers.Nadam(lr=LR), \n              optimizer=optimizers.Adam(lr=LR, amsgrad=True), \n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"id":"89sP9NTtHMFE"},"cell_type":"markdown","source":"---\n# Fit\n\n#### Обучаем и экспериментируем:"},{"metadata":{},"cell_type":"markdown","source":"*Следующий код представляет собой реализацию процесса экспериментального обучения модели.*\n\n*Он закомментирован, чтобы не тратить ограниченные ресурсы GPU при запуске ноутбука на Kaggle.*"},{"metadata":{"trusted":true,"id":"U_GkmGiUHMFF"},"cell_type":"code","source":"history = model_train(model, epochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"id":"AAXK3CMv6p_l","trusted":false},"cell_type":"code","source":"# show_stats(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"28_F_k54HMFP"},"cell_type":"code","source":"# сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model)\n# model_save()\n# model_evaluate()","execution_count":null,"outputs":[]},{"metadata":{"id":"UBJz7zL3HMFd"},"cell_type":"markdown","source":"#### Посмотрим графики обучения:"},{"metadata":{"_kg_hide-input":true,"trusted":true,"id":"FhHc-fu1HMFf"},"cell_type":"code","source":"# plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"hHn7edwqHMFl"},"cell_type":"markdown","source":"**С помощью экспериментов подобрали оптимальные параметры для болванки модели.**\n\n**Теперь перейдем к Fine-tuning.**"},{"metadata":{"id":"J2nzI7duHMFm"},"cell_type":"markdown","source":"---\n# Fine-tuning\n\n#### Применяем Transfer learning с Fine-tuning:\n\nСначала замораживаем все слои кроме новой \"головы\" и обучаем под новую задачу.\n\nЗатем будем последовательно размораживать сеть, обучая с уменьшенным Learning rate."},{"metadata":{"id":"6qsb8QjoHMFw"},"cell_type":"markdown","source":"#### Завернем ключевые этапы Fine-tuning в функции для удобства в реализации шагов:"},{"metadata":{"trusted":true,"id":"_QWVJyLhHMFw"},"cell_type":"code","source":"def model_layers_info(model):\n    '''\n    Показывает количество слоев в модели, а также\n    состояние открытости к обучению каждого слоя\n    (✔️ - готов к обучению, ✖️ - заморожен)\n    '''\n    print(f'Model <{model._name}> layers count:', len(model.layers), \n          f'(trainable vars: {len(model.trainable_variables)})', end='\\n\\n')\n    \n    for i in range(len(model.layers)):\n        l = model.layers[i]\n        print(f'{i + 1:03}', f'✔️' if l.trainable else '✖️', l.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"lQI5XQbTHMF1"},"cell_type":"code","source":"def finetune(base_model, n, model, opt):\n    '''\n    Реализует шаг Fine-tuning, размораживая 'n' последних слоев у \n    'base_model' (BatchNorm-слои остаются нетронутыми).\n    После этого модель 'model' компилируется в соответствии \n    с указанным оптимизатором 'opt'.\n    '''\n    # Отключаем обучаемость всей base_model\n    base_model.trainable = False\n    # Размораживаем n последних слоев\n    for layer in base_model.layers[-n:]:\n        # при fine-tuning BatchNorm-слои нужно оставлять замороженными\n        if not isinstance(layer, BatchNormalization): \n            layer.trainable = True\n    \n    model.compile(loss=\"categorical_crossentropy\", \n                  optimizer=opt, \n                  metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"id":"auREwI6CHMF6"},"cell_type":"markdown","source":"## Step 1"},{"metadata":{"trusted":true,"id":"IUsuHqsfHMF9","outputId":"a7c8fcde-df5e-47bd-de08-e87ec38aa26a"},"cell_type":"code","source":"IMG_SIZE   = 300\nBATCH_SIZE = 32\nLR         = 0.001\nVAL_SPLIT  = 0.05\n\n\n# Пересоздадим генераторы данных с новыми гиперпараметрами\ntrain_generator, validation_generator, test_subgenerator = rebuild_generators()","execution_count":null,"outputs":[]},{"metadata":{"id":"IHGp8dkB5lNB"},"cell_type":"markdown","source":"#### Берем более эффективную SOTA-модель EfficientNetB3 в качестве базовой модели:"},{"metadata":{"trusted":true,"id":"t919gp-vHMGC"},"cell_type":"code","source":"# base_model = EfficientNetB7(weights='imagenet', \nbase_model = EfficientNetB3(weights='imagenet', \n                            include_top=False, \n                            input_shape=(IMG_SIZE, IMG_SIZE, 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Сначала вручную собираем модель на базе полностью замороженной основы \n\n#### `base_model` (соответственно, веса, предобученные на imagenet, не затираются)"},{"metadata":{"trusted":true,"id":"gzBmoctWHMGK"},"cell_type":"code","source":"# Для этого отключаем её обучаемость\nbase_model.trainable = False\n\n# Задаем архитектуру \"головы\"\nhead = S([GlobalAveragePooling2D(), \n          \n          Dense(128, use_bias=False, kernel_regularizer='l2'), \n          BatchNormalization(axis=1), \n          Activation('relu'), \n\n          Dropout(DROPOUT_RATE),\n          Dense(10, activation='softmax')])\n\n# Собираем модель\nmodel = model_assembly(base_model, head)\n\n# Компилируем\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(lr=LR, amsgrad=True), \n              metrics=[\"accuracy\"])\n\n# Проверим результат\nmodel_layers_info(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"dkFNGfq7HMGR","outputId":"9c641d84-b5fe-4911-ba55-a5ee3ef39611"},"cell_type":"code","source":"# Обучаем\nhistory = model_train(model, epochs=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"NhSSZk3ZHMGU","outputId":"a26a98b5-be88-4166-da9d-0125eecdbc30"},"cell_type":"code","source":"show_stats(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"c-EbxtUvHMGZ","outputId":"2fd681b2-3ff1-4ad9-b726-432256604b26"},"cell_type":"code","source":"model_save(step=1)\nmodel_evaluate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"mwLCVN1zHMGc","outputId":"8ff43ff8-ff99-43a3-e1c7-5b642f5e8cfc"},"cell_type":"code","source":"plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"joQP7pUQHMGi"},"cell_type":"markdown","source":"## Step 2\n#### На втором шаге разморозим половину слоев base_model и дообучим модель с уменьшенной Learning rate."},{"metadata":{"trusted":true,"id":"LvQHYwxCHMGi"},"cell_type":"code","source":"LR = 0.0001\n\n\nfinetune(base_model, \n         n=int(len(base_model.layers) // 2),  # размораживаем половину слоев\n         model=model, \n         opt=optimizers.Adam(lr=LR, amsgrad=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"1FkuNxn9HMGr"},"cell_type":"code","source":"# Посмотрим количество слоев и их статус обучаемости\nmodel_layers_info(model)","execution_count":null,"outputs":[]},{"metadata":{"id":"apQiIEFwJ7TS","trusted":false},"cell_type":"code","source":"model.load_weights('best_model.hdf5')\nmodel_evaluate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"P4e2iDz0HMG0","outputId":"a5979d6e-4a5f-4531-c021-b8df0c7c4f53"},"cell_type":"code","source":"# Обучаем\nhistory = model_train(model, epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"ciPbrJQJHMG2","outputId":"ef77738f-527f-4d64-80a7-a918d4b2c70a"},"cell_type":"code","source":"show_stats(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"MeJryvRfHMG6","outputId":"36864800-e6a8-4c94-f555-50a90c496352"},"cell_type":"code","source":"model_save(step=2)\nmodel_evaluate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"dCcZoRhRHMG8","outputId":"0c31638e-f5dd-43fa-8c14-9cb279ab710a"},"cell_type":"code","source":"plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"pivO7VanHMG_"},"cell_type":"markdown","source":"## Step 3\n#### На третьем шаге разморозим все слои base_model и еще уменьшим Learning rate."},{"metadata":{"trusted":true,"id":"nEYbZncPHMG_"},"cell_type":"code","source":"LR = 0.00001\n\n# Разморозим все слои base_model\nfinetune(base_model, \n         n=len(base_model.layers),  # размораживаем все слои\n         model=model, \n         opt=optimizers.Adam(lr=LR, amsgrad=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"ST0r1BC3HMHB"},"cell_type":"code","source":"# Посмотрим количество слоев и их статус обучаемости\nmodel_layers_info(model)","execution_count":null,"outputs":[]},{"metadata":{"id":"7QotWbpxw66h","outputId":"cef77ec4-7626-4283-c617-e1a3b92f0ec7","trusted":false},"cell_type":"code","source":"model.load_weights('best_model.hdf5')\nmodel_evaluate()","execution_count":null,"outputs":[]},{"metadata":{"id":"DZPcEiNvsXNQ","outputId":"010b5aae-f254-4d6e-baa3-5bab6247e604","trusted":false},"cell_type":"code","source":"# Обучаем\nhistory = model_train(model, epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"id":"pBGCCFJxGeC9","outputId":"d8ca6ae1-0a90-4fff-e078-952be1b41e3d","trusted":false},"cell_type":"code","source":"show_stats(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"1AWwrStRHMHI","outputId":"798230e0-0cb5-46f6-ca75-6c21ff49b692"},"cell_type":"code","source":"model_save(step=3)\nmodel_evaluate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"DC3WpVLbHMHK","outputId":"699258c1-169c-4596-bf84-4db8099491a8"},"cell_type":"code","source":"plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"NR3VvccbHMHZ"},"cell_type":"markdown","source":"## Step 4\n#### На последнем шаге дообучаем сеть с увеличенным размером изображения.\n\nТакже придется уменьшить batch, иначе сеть не влезет в память GPU."},{"metadata":{"trusted":true,"id":"sKBXVXBcHMHZ","outputId":"837ace3d-b4b6-4a20-f736-12ed6cc74bc2"},"cell_type":"code","source":"IMG_SIZE             = 512\nBATCH_SIZE           = 8\nLR                   = 0.0001\n\n\n# Пересоздаем генераторы данных с новыми гиперпараметрами\ntrain_generator, validation_generator, test_subgenerator = rebuild_generators()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"aakZq1deHMHb"},"cell_type":"code","source":"# Загрузим предобученную сеть\nbase_model = EfficientNetB3(weights='imagenet', \n                            include_top=False, \n                            input_shape=(IMG_SIZE, IMG_SIZE, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"qiKhf13hHMHc"},"cell_type":"code","source":"# Задаем архитектуру \"головы\"\nhead = S([GlobalAveragePooling2D(), \n          \n          Dense(128, use_bias=False, kernel_regularizer='l2'), \n          BatchNormalization(axis=1), \n          Activation(\"relu\"), \n          Dropout(DROPOUT_RATE), \n          \n          Dense(10, activation='softmax')])\n\n# Собираем модель\nmodel = model_assembly(base_model, head)\n\n# Компилируем\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(lr=LR, amsgrad=True), \n              metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Kb2iX6C2HMHh"},"cell_type":"code","source":"# Посмотрим количество слоев и их статус обучаемости\nmodel_layers_info(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"OFoo3KH_HMHf","outputId":"4188c85b-8d66-413a-8e52-d68238b2cdba"},"cell_type":"code","source":"model.load_weights('best_model.hdf5')\nmodel_evaluate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"gQyUltNNHMHj","outputId":"bac7e9d2-9662-46a9-f159-ff6f3c587aac"},"cell_type":"code","source":"# Обучаем\nhistory = model_train(model, epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"nQcHjguRHMHl","outputId":"7ebdd6ee-556f-449d-964d-f2dcbeae59e9"},"cell_type":"code","source":"show_stats(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"11FBZytDHMHn","outputId":"0b85b088-cf2a-4bac-f007-72d524088b04"},"cell_type":"code","source":"model_save(step=4)\nmodel_evaluate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"63yALqIFHMHp"},"cell_type":"code","source":"plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{"id":"Wlbe87NrgNX2"},"cell_type":"markdown","source":"# Предсказание на тестовых данных"},{"metadata":{"trusted":true,"id":"vFXYnaqTeX4G","outputId":"2eedf359-497a-4984-dd47-3f2167929a83"},"cell_type":"code","source":"test_subgenerator.samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"uW21c14NHMH6","outputId":"f7e514da-0169-405f-dea9-9f2e350ead7d"},"cell_type":"code","source":"test_subgenerator.reset()\n\npredictions = model.predict_generator(test_subgenerator, verbose=1) \npredictions = np.argmax(predictions, axis=-1)\n\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v, k) for k, v in label_map.items()) # flip k, v\npredictions = [label_map[k] for k in predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"W8JV4FxOHMH7"},"cell_type":"code","source":"submission = pd.DataFrame({'Id': test_subgenerator.filenames, \n                           'Category': predictions}, \n                          columns=['Id', 'Category'])\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"Os-zWTQ-TZBM","trusted":false},"cell_type":"code","source":"# Сохраним submission\nnow = dt.now().strftime('[%d.%m.%Y]-[%H-%M]')\nsubmission_name = f'submission-{now}.csv'\nsubmission.to_csv(submission_name, index=False)\n\nprint('Submission saved')","execution_count":null,"outputs":[]},{"metadata":{"id":"GjY7t3wxe6HI"},"cell_type":"markdown","source":"# TTA (Test Time Augmentation)\nhttps://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d"},{"metadata":{"id":"OaSPY0aX3e4m","trusted":false},"cell_type":"code","source":"model.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"YElZGMmgvimd","outputId":"b5df16ba-7986-4668-cb4f-0bc438d9c82b"},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rotation_range=10, \n                                  brightness_range=[0.5, 1.5], \n                                  width_shift_range=0.1, \n                                  height_shift_range=0.1, \n                                  horizontal_flip=True)\n\ntest_subgenerator = test_datagen.flow_from_dataframe(\n    dataframe=sample_submission, \n    directory=PATH + 'test_upload/', \n    x_col='Id', \n    y_col=None, \n    target_size=(IMG_SIZE, IMG_SIZE), \n    batch_size=BATCH_SIZE, \n    class_mode=None, \n    shuffle=False, \n    seed=RANDOM_SEED\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"MBNu_s8pvimq","outputId":"e7d9fd07-b16d-443b-8c62-370eb4e50fc8"},"cell_type":"code","source":"tta_steps = 10   # берем среднее за 10 предсказаний\npredictions = []\n\nfor i in range(tta_steps):\n    preds = model.predict_generator(test_subgenerator, verbose=1)\n    predictions.append(preds)\n\npred = np.mean(predictions, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"s_Z7MsQYvim1"},"cell_type":"code","source":"predictions = np.argmax(pred, axis=-1)\n\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v, k) for k, v in label_map.items()) # flip k, v\n\npredictions = [label_map[k] for k in predictions]\n\nsubmission = pd.DataFrame({'Id': test_subgenerator.filenames, \n                           'Category': predictions})\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"3Tv2Qgx0vim3","outputId":"2cf568ae-6a67-427f-d4f2-d7c4d622f9c3"},"cell_type":"code","source":"# Сохраним submission\nnow = dt.now().strftime('[%d.%m.%Y]-[%H-%M]')\nsubmission_name = f'submission-{now}-TTA.csv'\nsubmission.to_csv(submission_name, index=False)\n\nprint('Submission saved')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"id":"qZa_SViDHMH-"},"cell_type":"code","source":"# Clean PATH\nimport shutil\nshutil.rmtree(PATH)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Заключение\n\n- Основное тестирование для подбора гиперпараметров было решено проводить на сети EfficientNetB0\n\n- Испытывались предобученные сети: EfficientNetE0, EfficientNetE3, EfficientNetE4, EfficientNetE6, EfficientNetE7;\n\nДля финальной модели была выбрана EfficientNetE3 из-за оптимального рекомендованного размера входного изображения (300x300)\n\n- Заметный прирост точности показало добавление в архитектуру \"головы\" BatchNormalization\n\n\n- Пробовались разные способы Augmentation, оптимальные параметры были выстравлены для финальной модели\n\n\n- Тестировались следующие оптимизаторы:\n    - Adam\n    - Nadam\n    - Adamax\n\nЛучший результат показал `Adam` с параметром `amsgrad=True`\n\n- Добавлена l2-регуляризация\n\n\n- Применены различные Keras CallBacks:\n  - ModelCheckpoint\n  - EarlyStopping\n  - ReduceLROnPlateau\n  - LearningRateScheduler\n  - TimingCallback\n  \n    \n- Испробованы разные техники управления LR:\n  - callback: LearningRateScheduler()\n  [[>]](https://keras.io/api/callbacks/learning_rate_scheduler/)\n  - callback: ReduceLROnPlateau()\n  [[>]](https://keras.io/api/callbacks/reduce_lr_on_plateau/)\n  - tf.keras.optimizers.schedules.ExponentialDecay()\n  [[>]](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay)\n\nДля финального решения была выбрана настройка `LearningRateScheduler(lambda x: LR * LR_DECAY_RATE ** x, verbose=1)`\n\n\n- Применена техника Test Time Augmentation, что дало небольшое улучшение точности.\n\n\nДля настройки финальной модели было проведено большое количество экспериментов с разными значениями гиперпараметров (размер изображения, размер batch, Learning rate, количество эпох, оптимизаторы).\n\nFine-tuning показал себя хорошей работающей техникой, однако лучший результат в этом проекте был достигнут простым обучением в течение 20 эпох модели EfficientNetE3 с выставленными оптимальными для неё гиперпараметрами и с добавленной Test Time Augmentation.\n\n\n---\nЧто не было сделано, но хотелось бы попробовать:\n\n- Stratified-разбиение\n- Динамическое увеличение размера картинки при Fine-tuning\n- Другие стратегии разморозки слоев\n- Cyclic Learning Rate\n- Ансамблирование предобученных нейросетей\n- Использование внешних датасетов для дообучения модели."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}