{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis\n",
    "import pandas as pd\n",
    "# Fileworks\n",
    "import pickle\n",
    "pickle.HIGHEST_PROTOCOL = 4  # for compability reasons\n",
    "\n",
    "# ML preprocessing\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'dataset/'\n",
    "SAMPLES_PATH = 'samples/'\n",
    "\n",
    "TSV_TRAIN = 'train.tsv'\n",
    "TSV_DEV = 'dev.tsv'\n",
    "TSV_TEST = 'test.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH + TSV_TRAIN, sep='\\t')\n",
    "df_dev = pd.read_csv(DATA_PATH + TSV_DEV, sep='\\t')\n",
    "df_test = pd.read_csv(DATA_PATH + TSV_TEST, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tuples = [(df_train, TSV_TRAIN), \n",
    "            (df_dev, TSV_DEV), \n",
    "            (df_test, TSV_TEST)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 564337 rows and 10 columns in train.tsv\n",
      "There are 16164 rows and 10 columns in dev.tsv\n",
      "There are 16164 rows and 10 columns in test.tsv\n"
     ]
    }
   ],
   "source": [
    "for df, tsv_name in d_tuples:\n",
    "    print(f'There are {df.shape[0]} rows and {df.shape[1]} columns in {tsv_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Accented Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll leave only samples with labeled accents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 317182 rows with accents train.tsv\n",
      "There are 1874 rows with accents dev.tsv\n",
      "There are 1519 rows with accents test.tsv\n"
     ]
    }
   ],
   "source": [
    "for df, tsv_name in d_tuples:\n",
    "    df.query('accent == accent', inplace=True)\n",
    "    print(f'There are {df.shape[0]} rows with accents {tsv_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, check what fraction is each dataset relative to the total amount of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accented dataset full size: 320575 rows\n",
      "\n",
      "train.tsv is 98.94% of full dataset\n",
      "dev.tsv is 0.58% of full dataset\n",
      "test.tsv is 0.47% of full dataset\n"
     ]
    }
   ],
   "source": [
    "full_size = sum([len(df) for df in [t[0] for t in d_tuples]])\n",
    "print(f'Accented dataset full size: {full_size} rows\\n')\n",
    "\n",
    "for df, tsv_name in d_tuples:\n",
    "    print(f'{tsv_name} is {(df.shape[0] / full_size * 100):.2f}% of full dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..which is obviously too little. So, let's concatenate all data into a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created full accented dataset with 320575 rows and 10 columns\n"
     ]
    }
   ],
   "source": [
    "df_full = pd.concat([df for df in [t[0] for t in d_tuples]])\n",
    "print(f'Created full accented dataset with {df_full.shape[0]} rows and {df_full.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's explore the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cb5bd9ad996218619531511ae2600aa61055005f910e7c...</td>\n",
       "      <td>common_voice_en_1027059.mp3</td>\n",
       "      <td>Little things please little minds</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>cc6516333444de42e6d5a07afe5f65085d09df0f45c3c2...</td>\n",
       "      <td>common_voice_en_21788001.mp3</td>\n",
       "      <td>Unfortunately, Adam overloads the computer, fr...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>cc6516333444de42e6d5a07afe5f65085d09df0f45c3c2...</td>\n",
       "      <td>common_voice_en_21788002.mp3</td>\n",
       "      <td>Nepal Loktantrik Primary School is one of the ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>cc6516333444de42e6d5a07afe5f65085d09df0f45c3c2...</td>\n",
       "      <td>common_voice_en_21788003.mp3</td>\n",
       "      <td>In the same article, Gardner denied that he co...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>cc6516333444de42e6d5a07afe5f65085d09df0f45c3c2...</td>\n",
       "      <td>common_voice_en_21788004.mp3</td>\n",
       "      <td>During her literary career, she has written po...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            client_id  \\\n",
       "24  cb5bd9ad996218619531511ae2600aa61055005f910e7c...   \n",
       "72  cc6516333444de42e6d5a07afe5f65085d09df0f45c3c2...   \n",
       "73  cc6516333444de42e6d5a07afe5f65085d09df0f45c3c2...   \n",
       "74  cc6516333444de42e6d5a07afe5f65085d09df0f45c3c2...   \n",
       "75  cc6516333444de42e6d5a07afe5f65085d09df0f45c3c2...   \n",
       "\n",
       "                            path  \\\n",
       "24   common_voice_en_1027059.mp3   \n",
       "72  common_voice_en_21788001.mp3   \n",
       "73  common_voice_en_21788002.mp3   \n",
       "74  common_voice_en_21788003.mp3   \n",
       "75  common_voice_en_21788004.mp3   \n",
       "\n",
       "                                             sentence  up_votes  down_votes  \\\n",
       "24                  Little things please little minds         2           0   \n",
       "72  Unfortunately, Adam overloads the computer, fr...         2           0   \n",
       "73  Nepal Loktantrik Primary School is one of the ...         2           0   \n",
       "74  In the same article, Gardner denied that he co...         2           0   \n",
       "75  During her literary career, she has written po...         2           1   \n",
       "\n",
       "         age gender accent locale segment  \n",
       "24  twenties   male     us     en     NaN  \n",
       "72  thirties   male     us     en     NaN  \n",
       "73  thirties   male     us     en     NaN  \n",
       "74  thirties   male     us     en     NaN  \n",
       "75  thirties   male     us     en     NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320575 entries, 24 to 16134\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   client_id   320575 non-null  object\n",
      " 1   path        320575 non-null  object\n",
      " 2   sentence    320575 non-null  object\n",
      " 3   up_votes    320575 non-null  int64 \n",
      " 4   down_votes  320575 non-null  int64 \n",
      " 5   age         315295 non-null  object\n",
      " 6   gender      315807 non-null  object\n",
      " 7   accent      320575 non-null  object\n",
      " 8   locale      320575 non-null  object\n",
      " 9   segment     1 non-null       object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 26.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_id       7336\n",
       "path          320575\n",
       "sentence      320575\n",
       "up_votes          16\n",
       "down_votes         7\n",
       "age                9\n",
       "gender             3\n",
       "accent            17\n",
       "locale             1\n",
       "segment            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 7336 unique speakers\n",
    "- Each spoken sentence is unique\n",
    "- 9 types of age\n",
    "- 3 types of gender\n",
    "- 17 unique English accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode client_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode `client_id` feature for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    id_5830\n",
       "72    id_5849\n",
       "73    id_5849\n",
       "74    id_5849\n",
       "75    id_5849\n",
       "Name: client_id, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_encoder = OrdinalEncoder(dtype=int)\n",
    "df_full['client_id'] = ordinal_encoder.fit_transform(df_full[['client_id'][:]])\n",
    "df_full['client_id'] = df_full['client_id'].apply(lambda x: f'id_{x}')\n",
    "\n",
    "df_full['client_id'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Votes Disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll engineer a new feature called  `'votes_disparity_rate'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    0.398656\n",
       "72    0.398656\n",
       "73    0.398656\n",
       "74    0.398656\n",
       "75    0.087053\n",
       "Name: votes_disparity_rate, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def disparity_rate(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''Creates votes_disparity_rate feature, which may denote some useful information'''\n",
    "    make_disparity_rate = lambda u, d: ((u - d) / max(u, d)) * (np.log(u - d) + 1)\n",
    "    df['votes_disparity_rate'] = df.apply(\n",
    "        lambda r: make_disparity_rate(r['up_votes'], r['down_votes']), \n",
    "        axis=1\n",
    "    )\n",
    "    vdr_array = df['votes_disparity_rate'].values.reshape(-1, 1)\n",
    "    df['votes_disparity_rate'] = MinMaxScaler().fit_transform(vdr_array)\n",
    "    return df\n",
    "\n",
    "df_full = disparity_rate(df_full)\n",
    "\n",
    "df_full['votes_disparity_rate'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove an absolutely empty attribute `'segment'` and unnecessary `'locale'` (1 unique value):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full[df_full['accent'].notna()]\n",
    "df_full = df_full.drop(['segment', 'locale'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check each accent quantities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "us                171217\n",
       "england            46836\n",
       "indian             33637\n",
       "australia          24230\n",
       "canada             21077\n",
       "scotland            6204\n",
       "ireland             3938\n",
       "newzealand          3378\n",
       "african             3188\n",
       "philippines         2295\n",
       "singapore           2001\n",
       "hongkong            1256\n",
       "malaysia             560\n",
       "wales                312\n",
       "other                276\n",
       "bermuda              165\n",
       "southatlandtic         5\n",
       "Name: accent, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full['accent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove accents with counts less than 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_counts = df_full['accent'].value_counts()\n",
    "accents_list = acc_counts[acc_counts >= 1000].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "us             171217\n",
       "england         46836\n",
       "indian          33637\n",
       "australia       24230\n",
       "canada          21077\n",
       "scotland         6204\n",
       "ireland          3938\n",
       "newzealand       3378\n",
       "african          3188\n",
       "philippines      2295\n",
       "singapore        2001\n",
       "hongkong         1256\n",
       "Name: accent, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = df_full[df_full['accent'].isin(accents_list)]\n",
    "\n",
    "df_full['accent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 319257 entries, 24 to 16134\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   client_id             319257 non-null  object \n",
      " 1   path                  319257 non-null  object \n",
      " 2   sentence              319257 non-null  object \n",
      " 3   up_votes              319257 non-null  int64  \n",
      " 4   down_votes            319257 non-null  int64  \n",
      " 5   age                   313977 non-null  object \n",
      " 6   gender                314496 non-null  object \n",
      " 7   accent                319257 non-null  object \n",
      " 8   votes_disparity_rate  319257 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_id                 7160\n",
       "path                    319257\n",
       "sentence                319257\n",
       "up_votes                    16\n",
       "down_votes                   7\n",
       "age                          9\n",
       "gender                       3\n",
       "accent                      12\n",
       "votes_disparity_rate        46\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe now consists of:\n",
      "12 unique accents\n",
      "319257 rows, 9 columns\n"
     ]
    }
   ],
   "source": [
    "print('Dataframe now consists of:')\n",
    "print(f'{df_full[\"accent\"].value_counts().count()} unique accents')\n",
    "print(f'{len(df_full)} rows, {len(df_full.columns)} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate New Metainfo Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_meta_name = 'source_df.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written accented samples dataset to: source_df.h5 (319257 rows, 9 columns)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macsunmood\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2603: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['client_id', 'path', 'sentence', 'age', 'gender', 'accent'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "df_full.to_hdf(DATA_PATH + new_meta_name, 'source_df', mode='w', index=False)\n",
    "\n",
    "shape = f'{df_full.shape[0]} rows, {df_full.shape[1]} columns'\n",
    "print(f'Successfully written accented samples dataset to: {new_meta_name} ({shape})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Delete Unnecessary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def filescount(dir_name):\n",
    "    '''Counts files in the dir'''\n",
    "    return len([f for f in os.listdir(dir_name) \n",
    "                if os.path.isfile(os.path.join(dir_name, f))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_junk(csv_file):\n",
    "    '''Removes unnecessary junk'''\n",
    "    print(f'Source CSV file: {csv_file}')\n",
    "    \n",
    "    # make list of proper files with accents\n",
    "    df = pd.read_csv(DATA_PATH + csv_file)\n",
    "    ok_list = df['filename'].tolist()\n",
    "\n",
    "    # make array with all files present in the target directory\n",
    "    directory = ntpath.split(ok_list[0])[0]\n",
    "    target_dir = DATA_PATH + directory\n",
    "    total_count = filescount(target_dir)\n",
    "    files = target_dir.walkfiles('*.mp3')\n",
    "    \n",
    "    # delete all files with no accents\n",
    "    print(f'Target dir: {target_dir} (contains {total_count} files in total)')\n",
    "    print('Removing files with no accent label..')\n",
    "    \n",
    "    del_count = 0\n",
    "    for f in files:\n",
    "        filename = directory + '/' + ntpath.basename(f)\n",
    "        if filename not in ok_list:\n",
    "            del_count += 1\n",
    "            f.remove()\n",
    "    \n",
    "    print(f'Total files removed: {del_count}')\n",
    "    print(f'Files remaining: {total_count - del_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source CSV file: cv-valid-test-accents.csv\n",
      "Target dir: dataset/cv-valid-test contains 3995 files in total\n",
      "Removing files with no accent label..\n",
      "Total files removed: 2657\n",
      "Files remaining: 1338\n"
     ]
    }
   ],
   "source": [
    "# remove_junk(acc_suffix(CSVFILE_TRAIN))\n",
    "# remove_junk(acc_suffix(CSVFILE_DEV))\n",
    "remove_junk(acc_suffix(CSVFILE_TEST))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "761px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
